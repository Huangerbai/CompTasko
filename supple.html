<!DOCTYPE html>
<html>
	<head>
		<META HTTP-EQUIV="Cache-Control" CONTENT="no-cache, must-revalidate">
		<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
		<script src="https://code.jquery.com/jquery-3.2.1.min.js"></script>
		<script src="./papaparse.min.js"></script>
		<title>Supplementary Material</title>
        <style type="text/css">
            body{
            	background-color: white;
            }
			img{
				max-width:80%;
				max-height:80%;
				width:auto;
				height:auto;
			}
            .button {
                width: 90px;
                height: 40px;
                border-radius: 2px;
                border: 0px solid #ccc;
                font-size: 20px;
                color: white;
                background-color: black;
            }
			.button_score {
                width: 90px;
                height: 40px;
                border-radius: 2px;
                border: 0px solid #ccc;
                font-size: 20px;
                color: white;
                background-color: gray;
			}
			.button_score_select {
                width: 90px;
                height: 40px;
                border-radius: 2px;
                border: 0px solid #ccc;
                font-size: 20px;
                color: white;
                background-color: red;
			}
			.mt{
				border-collapse:collapse;
				border:1px solid black;
			}
			.mt tr{
				border-bottom:1px solid black;
			}
        </style>
	</head>

  <body>
  	<div align="Center" style="padding:30px 100px 30px 100px;">
		<p id="title"> <font size="6"> Video Coding for Machines: Compact Visual Representation Compression for Intelligent Collaborative Analytics </font> </p>
		<p><font size="6"> (Supplementary Material) </font></p>
		<br>
		<p> Wenhan Yang*, Haofeng Huang*, Yueyu Hu*, Ling-Yu Duan, Jiaying Liu</p>
		<br>
		<br>
		
		<p align="left"><font size="5"> 1. Detailed Network Structures</font></p>
		<p align="left">Our feature extractor and analytics models follow the encoder and decoder of the taskonomy. <br />
<b>Feature Extractor</b>: For all tasks, the ResNet-50 encoder is utilized, excluding average pooling, and the last convolution with a stride of 2 is substituted with one having a stride of 1. The size of the output is 16&times;16&times;2048, and a 3&times;3 convolution is applied to transform the output to a final representation. The size of the final feature is 16&times;16&times;8. <br />
<b>Analytics Model</b>: The analytics model adopts a structure of a 15-layer fully convolutional network, including the preceding 5 convolutional layers, interconnected with alternating convolution and convolution transpose layers. <br />
<b>Transfer Mapping</b>: It consists of alternating convolution and ReLU modules. The detailed structure is provided in Table 1. The input dimension depends on the size of the concatenation of the previously extracted features, which is set to 24.
</p>
		<br>
		
		<p>Table 1. Detailed structures of the proposed transfer mapping.</p>
		<table class='mt'>
		<tr></tr>
		<tr>
		<th align="middle">&nbsp;&nbsp;Layer&nbsp;&nbsp;</th>
		<th>&emsp; </th>
		<th align="middle">#Input Channel</th>
		<th>&emsp; </th>
		<th align="middle">#Output Channel</th>
		<th>&emsp; </th>
		<th align="middle">Kernel Size</th>
		</tr>
		
		<tr>
		<td align="middle">Conv</td>
		<th>&emsp; </th>
		<td align="middle">24</td>
		<th>&emsp; </th>
		<td align="middle">1024</td>
		<th>&emsp; </th>
		<td align="middle">3</td>
		</tr>
		<tr>
		<td align="middle">ReLU</td>
		<th>&emsp; </th>
		<td align="middle">-</td>
		<th>&emsp; </th>
		<td align="middle">-</td>
		<th>&emsp; </th>
		<td align="middle">-</td>
		</tr>
		
		<tr>
		<td align="middle">Conv</td>
		<th>&emsp; </th>
		<td align="middle">1024</td>
		<th>&emsp; </th>
		<td align="middle">1024</td>
		<th>&emsp; </th>
		<td align="middle">3</td>
		</tr>
		<tr>
		<td align="middle">ReLU</td>
		<th>&emsp; </th>
		<td align="middle">-</td>
		<th>&emsp; </th>
		<td align="middle">-</td>
		<th>&emsp; </th>
		<td align="middle">-</td>
		</tr>
		
		<tr>
		<td align="middle">Conv</td>
		<th>&emsp; </th>
		<td align="middle">1024</td>
		<th>&emsp; </th>
		<td align="middle">512</td>
		<th>&emsp; </th>
		<td align="middle">3</td>
		</tr>
		<tr>
		<td align="middle">ReLU</td>
		<th>&emsp; </th>
		<td align="middle">-</td>
		<th>&emsp; </th>
		<td align="middle">-</td>
		<th>&emsp; </th>
		<td align="middle">-</td>
		</tr>
		
		<tr>
		<td align="middle">Conv</td>
		<th>&emsp; </th>
		<td align="middle">512</td>
		<th>&emsp; </th>
		<td align="middle">256</td>
		<th>&emsp; </th>
		<td align="middle">3</td>
		</tr>
		<tr>
		<td align="middle">ReLU</td>
		<th>&emsp; </th>
		<td align="middle">-</td>
		<th>&emsp; </th>
		<td align="middle">-</td>
		<th>&emsp; </th>
		<td align="middle">-</td>
		</tr>
		
		<tr>
		<td align="middle">Conv</td>
		<th>&emsp; </th>
		<td align="middle">256</td>
		<th>&emsp; </th>
		<td align="middle">128</td>
		<th>&emsp; </th>
		<td align="middle">3</td>
		</tr>
		<tr>
		<td align="middle">ReLU</td>
		<th>&emsp; </th>
		<td align="middle">-</td>
		<th>&emsp; </th>
		<td align="middle">-</td>
		<th>&emsp; </th>
		<td align="middle">-</td>
		</tr>
		
		<tr>
		<td align="middle">Conv</td>
		<th>&emsp; </th>
		<td align="middle">128</td>
		<th>&emsp; </th>
		<td align="middle">128</td>
		<th>&emsp; </th>
		<td align="middle">3</td>
		</tr>
		
		
		</table>
		<br>

<p align="left"><b>Inverse Transfer</b>: It consists of alternating convolution and ReLU modules. The detailed structure is provided in Table 2.</p>
		
		<p>Table 2. Detailed structures of the proposed inverse transfer.</p>
		<table class='mt'>
		<tr></tr>
		<tr>
		<th align="middle">&nbsp;&nbsp;Layer&nbsp;&nbsp;</th>
		<th>&emsp; </th>
		<th align="middle">#Input Channel</th>
		<th>&emsp; </th>
		<th align="middle">#Output Channel</th>
		<th>&emsp; </th>
		<th align="middle">Kernel Size</th>
		</tr>
		
		<tr>
		<td align="middle">Conv</td>
		<th>&emsp; </th>
		<td align="middle">128</td>
		<th>&emsp; </th>
		<td align="middle">1024</td>
		<th>&emsp; </th>
		<td align="middle">3</td>
		</tr>
		<tr>
		<td align="middle">ReLU</td>
		<th>&emsp; </th>
		<td align="middle">-</td>
		<th>&emsp; </th>
		<td align="middle">-</td>
		<th>&emsp; </th>
		<td align="middle">-</td>
		</tr>
		
		<tr>
		<td align="middle">Conv</td>
		<th>&emsp; </th>
		<td align="middle">1024</td>
		<th>&emsp; </th>
		<td align="middle">1024</td>
		<th>&emsp; </th>
		<td align="middle">3</td>
		</tr>
		<tr>
		<td align="middle">ReLU</td>
		<th>&emsp; </th>
		<td align="middle">-</td>
		<th>&emsp; </th>
		<td align="middle">-</td>
		<th>&emsp; </th>
		<td align="middle">-</td>
		</tr>
		
		<tr>
		<td align="middle">Conv</td>
		<th>&emsp; </th>
		<td align="middle">1024</td>
		<th>&emsp; </th>
		<td align="middle">512</td>
		<th>&emsp; </th>
		<td align="middle">3</td>
		</tr>
		<tr>
		<td align="middle">ReLU</td>
		<th>&emsp; </th>
		<td align="middle">-</td>
		<th>&emsp; </th>
		<td align="middle">-</td>
		<th>&emsp; </th>
		<td align="middle">-</td>
		</tr>
		
		<tr>
		<td align="middle">Conv</td>
		<th>&emsp; </th>
		<td align="middle">512</td>
		<th>&emsp; </th>
		<td align="middle">256</td>
		<th>&emsp; </th>
		<td align="middle">3</td>
		</tr>
		<tr>
		<td align="middle">ReLU</td>
		<th>&emsp; </th>
		<td align="middle">-</td>
		<th>&emsp; </th>
		<td align="middle">-</td>
		<th>&emsp; </th>
		<td align="middle">-</td>
		</tr>
		
		<tr>
		<td align="middle">Conv</td>
		<th>&emsp; </th>
		<td align="middle">256</td>
		<th>&emsp; </th>
		<td align="middle">128</td>
		<th>&emsp; </th>
		<td align="middle">3</td>
		</tr>
		<tr>
		<td align="middle">ReLU</td>
		<th>&emsp; </th>
		<td align="middle">-</td>
		<th>&emsp; </th>
		<td align="middle">-</td>
		<th>&emsp; </th>
		<td align="middle">-</td>
		</tr>
		
		<tr>
		<td align="middle">Conv</td>
		<th>&emsp; </th>
		<td align="middle">128</td>
		<th>&emsp; </th>
		<td align="middle">24</td>
		<th>&emsp; </th>
		<td align="middle">3</td>
		</tr>
		
		
		</table>
		<br>
	
<p align="left"><b>Hyper Analysis Transform</b>: Its detailed structure is shown in Table 3.</p>
		<br>
		<p>Table 3. Detailed structures of the proposed hyper analysis transform.</p>
		<table class='mt'>
		<tr></tr>
		<tr>
		<th align="middle">&nbsp;&nbsp;Layer&nbsp;&nbsp;</th>
		<th>&emsp; </th>
		<th align="middle">#Input Channel</th>
		<th>&emsp; </th>
		<th align="middle">#Output Channel</th>
		<th>&emsp; </th>
		<th align="middle">Kernel Size</th>
		</tr>
		
		<tr>
		<td align="middle">Conv</td>
		<th>&emsp; </th>
		<td align="middle">128</td>
		<th>&emsp; </th>
		<td align="middle">1024</td>
		<th>&emsp; </th>
		<td align="middle">3</td>
		</tr>
		<tr>
		<td align="middle">ReLU</td>
		<th>&emsp; </th>
		<td align="middle">-</td>
		<th>&emsp; </th>
		<td align="middle">-</td>
		<th>&emsp; </th>
		<td align="middle">-</td>
		</tr>
		
		<tr>
		<td align="middle">Conv</td>
		<th>&emsp; </th>
		<td align="middle">1024</td>
		<th>&emsp; </th>
		<td align="middle">1024</td>
		<th>&emsp; </th>
		<td align="middle">3</td>
		</tr>
		<tr>
		<td align="middle">ReLU</td>
		<th>&emsp; </th>
		<td align="middle">-</td>
		<th>&emsp; </th>
		<td align="middle">-</td>
		<th>&emsp; </th>
		<td align="middle">-</td>
		</tr>
		
		<tr>
		<td align="middle">AdaptiveAvgPool</td>
		<th>&emsp; </th>
		<td align="middle">-</td>
		<th>&emsp; </th>
		<td align="middle">-</td>
		<th>&emsp; </th>
		<td align="middle">-</td>
		</tr>
		<tr>
		<td align="middle">Flatten</td>
		<th>&emsp; </th>
		<td align="middle">-</td>
		<th>&emsp; </th>
		<td align="middle">-</td>
		<th>&emsp; </th>
		<td align="middle">-</td>
		</tr>
		
		<tr>
		<td align="middle">Linear</td>
		<th>&emsp; </th>
		<td align="middle">1024</td>
		<th>&emsp; </th>
		<td align="middle">512</td>
		<th>&emsp; </th>
		<td align="middle">3</td>
		</tr>
		<tr>
		<td align="middle">ReLU</td>
		<th>&emsp; </th>
		<td align="middle">-</td>
		<th>&emsp; </th>
		<td align="middle">-</td>
		<th>&emsp; </th>
		<td align="middle">-</td>
		</tr>
		
		<tr>
		<td align="middle">Linear</td>
		<th>&emsp; </th>
		<td align="middle">512</td>
		<th>&emsp; </th>
		<td align="middle">128</td>
		<th>&emsp; </th>
		<td align="middle">-</td>
		</tr>
		</table>
		<br>
		
<p align="left"><b>Hyper Synthesis Transform</b>: The structure of hyper synthesis transform is shown in Table 4.</p>
		<br>
		<p>Table 4. Detailed structures of the proposed hyper synthesis transform.</p>
		<table class='mt'>
		<tr></tr>
		<tr>
		<th align="middle">&nbsp;&nbsp;Layer&nbsp;&nbsp;</th>
		<th>&emsp; </th>
		<th align="middle">#Input Channel</th>
		<th>&emsp; </th>
		<th align="middle">#Output Channel</th>
		<th>&emsp; </th>
		<th align="middle">Kernel Size</th>
		</tr>
		
		<tr>
		<td align="middle">Linear</td>
		<th>&emsp; </th>
		<td align="middle">128</td>
		<th>&emsp; </th>
		<td align="middle">512</td>
		<th>&emsp; </th>
		<td align="middle">-</td>
		</tr>
		<tr>
		<td align="middle">ReLU</td>
		<th>&emsp; </th>
		<td align="middle">-</td>
		<th>&emsp; </th>
		<td align="middle">-</td>
		<th>&emsp; </th>
		<td align="middle">-</td>
		</tr>
		
		<tr>
		<td align="middle">Linear</td>
		<th>&emsp; </th>
		<td align="middle">512</td>
		<th>&emsp; </th>
		<td align="middle">512</td>
		<th>&emsp; </th>
		<td align="middle">-</td>
		</tr>
		<tr>
		<td align="middle">ReLU</td>
		<th>&emsp; </th>
		<td align="middle">-</td>
		<th>&emsp; </th>
		<td align="middle">-</td>
		<th>&emsp; </th>
		<td align="middle">-</td>
		</tr>
		
		<tr>
		<td align="middle">Linear</td>
		<th>&emsp; </th>
		<td align="middle">512</td>
		<th>&emsp; </th>
		<td align="middle">512</td>
		<th>&emsp; </th>
		<td align="middle">-</td>
		</tr>
		<tr>
		<td align="middle">ReLU</td>
		<th>&emsp; </th>
		<td align="middle">-</td>
		<th>&emsp; </th>
		<td align="middle">-</td>
		<th>&emsp; </th>
		<td align="middle">-</td>
		</tr>
		
		<tr>
		<td align="middle">Linear</td>
		<th>&emsp; </th>
		<td align="middle">512</td>
		<th>&emsp; </th>
		<td align="middle">512 &times; 128</td>
		<th>&emsp; </th>
		<td align="middle">-</td>
		</tr>
		
		</table>
		<br>
<p align="left"><b>CodeBook</b>: A vector with dimensions of 512&times;16&times;16, which will be further multiplied with an incoming vector to obtain a feature tensor whose spatial size is 16&times;16. <br />
<b>CodeBookPrediction</b>: the module predicts the probabilistic distribution with the codebook to estimate and constrain entropy. The transform that converts the feature outputted from the codebook to the distributionâ€™s parameters is illustrated in detail in Table 5.</p>
<br>
<p>Table 5. Detailed structures of the proposed CodeBookPrediction module.</p>
		<table class='mt'>
		<tr></tr>
		<tr>
		<th align="middle">&nbsp;&nbsp;Layer&nbsp;&nbsp;</th>
		<th>&emsp; </th>
		<th align="middle">#Input Channel</th>
		<th>&emsp; </th>
		<th align="middle">#Output Channel</th>
		<th>&emsp; </th>
		<th align="middle">Kernel Size</th>
		<th>&emsp; </th>
		<th align="middle">Slope</th>
		</tr>
		
		<tr>
		<td align="middle">Conv</td>
		<th>&emsp; </th>
		<td align="middle">32</td>
		<th>&emsp; </th>
		<td align="middle">32</td>
		<th>&emsp; </th>
		<td align="middle">3</td>
		<th>&emsp; </th>
		<td align="middle">-</td>
		</tr>
		<tr>
		<td align="middle">LeakyReLU</td>
		<th>&emsp; </th>
		<td align="middle">-</td>
		<th>&emsp; </th>
		<td align="middle">-</td>
		<th>&emsp; </th>
		<td align="middle">-</td>
		<th>&emsp; </th>
		<td align="middle">0.2</td>
		</tr>
		
		<tr>
		<td align="middle">Conv</td>
		<th>&emsp; </th>
		<td align="middle">32</td>
		<th>&emsp; </th>
		<td align="middle">32</td>
		<th>&emsp; </th>
		<td align="middle">3</td>
		<th>&emsp; </th>
		<td align="middle">-</td>
		</tr>
		<tr>
		<td align="middle">LeakyReLU</td>
		<th>&emsp; </th>
		<td align="middle">-</td>
		<th>&emsp; </th>
		<td align="middle">-</td>
		<th>&emsp; </th>
		<td align="middle">-</td>
		<th>&emsp; </th>
		<td align="middle">0.2</td>
		</tr>
		
		<tr>
		<td align="middle">Conv</td>
		<th>&emsp; </th>
		<td align="middle">32</td>
		<th>&emsp; </th>
		<td align="middle">32</td>
		<th>&emsp; </th>
		<td align="middle">3</td>
		<th>&emsp; </th>
		<td align="middle">-</td>
		</tr>
		<tr>
		<td align="middle">LeakyReLU</td>
		<th>&emsp; </th>
		<td align="middle">-</td>
		<th>&emsp; </th>
		<td align="middle">-</td>
		<th>&emsp; </th>
		<td align="middle">-</td>
		<th>&emsp; </th>
		<td align="middle">0.2</td>
		</tr>
		
		<tr>
		<td align="middle">Conv</td>
		<th>&emsp; </th>
		<td align="middle">32</td>
		<th>&emsp; </th>
		<td align="middle">256</td>
		<th>&emsp; </th>
		<td align="middle">3</td>
		<th>&emsp; </th>
		<td align="middle">-</td>
		</tr>
		
		</table>
		<br>
<p align="left">More details of other modules related to the compression or analytics models, e.g. Gaussian Bottleneck,  follow the basic setting in [1] or the common setting of end-to-end optimized compression methods.</p>
		<br>
		
		<br>
		<p align="left">References</p>
		<p align="left">[1] Amir R. Zamir, Alexander Sax, William Shen, Leonidas J Guibas, Jitendra Malik, and Silvio Savarese. Taskonomy: Disentangling task transfer learning. In Proc. of IEEE conference on Computer Vision and Pattern Recognition, 2018.</p>
		
	</div>
  </body>
</html>
